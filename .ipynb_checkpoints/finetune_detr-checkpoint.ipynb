{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-confidence",
   "metadata": {},
   "source": [
    "# Prep\n",
    "\n",
    "Setting up some prior functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rational-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-interim",
   "metadata": {},
   "source": [
    "# Load a model\n",
    "\n",
    "First we have to decide if our model should be pretrained. \n",
    "\n",
    "This greatly depends on the size of a dataset. Smaller datasets rely more on finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "printable-option",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "\n",
    "if pretrained:\n",
    "    # Get pretrained weights\n",
    "    checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                # url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "                # url='https://dl.fbaipublicfiles.com/detr/detr-r101-2c7b67e5.pth',\n",
    "                # url='https://dl.fbaipublicfiles.com/detr/detr-r101-dc5-a2e86def.pth',\n",
    "                url='https://dl.fbaipublicfiles.com/detr/detr-r50-dc5-f0fb7ef5.pth',\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "                map_location='cpu',\n",
    "                check_hash=True)\n",
    "\n",
    "    # Remove class weights\n",
    "    del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "    del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "    # SaveOGH\n",
    "    torch.save(checkpoint,\n",
    "               'detr-r50-dc5_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-version",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We use the main.py script to run our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hazardous-possibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/anazeri/detr_finetune/main.py\", line 10, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "  --dataset_file $dataset_file \\\n",
    "  --coco_path $dataDir \\\n",
    "  --output_dir $outDir \\\n",
    "  --resume $resume \\\n",
    "  --num_classes $num_classes \\\n",
    "  --lr 1e-5 \\\n",
    "  --lr_backbone 1e-6 \\\n",
    "  --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-sister",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Quick and easy overview of the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'class_error',\n",
    "    'cardinality_error_unscaled',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Detr_env1",
   "language": "python",
   "name": "detr_env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
